{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from functions import *\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from functions import * \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate as cvt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from copy import deepcopy as dp\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = load_pkl(r\"C:\\Users\\HEndo\\Documents\\GitHub\\zemi\\cleaned_corpus\\augmented_corpus.pkl\")\n",
    "test_a, train_a = load_pkl(r\"C:\\Users\\HEndo\\Documents\\GitHub\\zemi\\cleaned_corpus\\augmented_org_ans.pkl\")\n",
    "train_X = dp(train)\n",
    "train_Y = dp(train_a)\n",
    "sw = stopwords.words('english') + ['hes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.enable_default_handler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "    '_min': trial.suggest_uniform('_min', 1e-3, 8*1e-3),\n",
    "    '_max': trial.suggest_uniform('_max', 0.7, 0.9),\n",
    "    'mx_depth': trial.suggest_discrete_uniform('mx_depth', 10, 500, 10),\n",
    "    'mn_sp': trial.suggest_uniform('mn_sp', 0.1, 0.3),\n",
    "    'mx_feat': trial.suggest_uniform('mx_feat', 0.8, 1.0)\n",
    "    }\n",
    "    data = list(zip(train_X, train_Y))\n",
    "    random.shuffle(data)\n",
    "    ff_train, ff_train_a = zip(*data)\n",
    "    ff_train = [' '.join(text) for text in ff_train]\n",
    "    vect = TfidfVectorizer(stop_words=sw,tokenizer=tokenize, \n",
    "                          min_df= params['_min'], max_df=params['_max'], \n",
    "                          ngram_range=(1,2))\n",
    "    tfidf = vect.fit_transform(ff_train)\n",
    "    tree = dtc(max_depth=params['mx_depth'], \n",
    "               min_samples_split= params['mn_sp'],\n",
    "               max_features= params['mx_feat']\n",
    "              )\n",
    "\n",
    "    scores = cvt(tree, tfidf, ff_train_a, cv = 4, return_train_score= True, scoring = 'f1_macro', )\n",
    "    test_s = scores['test_score'].mean()\n",
    "    train_s = scores['train_score'].mean()\n",
    "    f_score = 1.0 - float(test_s) + float(abs(train_s-test_s))/2.0\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-02-27 14:48:12,677] Finished trial 100 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n",
      "[I 2019-02-27 14:48:13,940] Finished trial 100 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n",
      "[I 2019-02-27 14:48:15,042] Finished trial 100 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n",
      "[I 2019-02-27 14:49:54,561] Finished trial 200 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n",
      "[I 2019-02-27 14:51:54,889] Finished trial 300 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n",
      "[I 2019-02-27 14:53:45,071] Finished trial 400 / 500. Current best value is 0.21809442208226226 with parameters: {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=500, n_jobs = -1, verb_pace=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(trial):\n",
    "    params = {\n",
    "    'mx_depth': trial.suggest_discrete_uniform('mx_depth', 10, 100, 10),\n",
    "    }\n",
    "    data = list(zip(train_X, train_Y))\n",
    "    random.shuffle(data)\n",
    "    ff_train, ff_train_a = zip(*data)\n",
    "    ff_train = [' '.join(text) for text in ff_train]\n",
    "    vect = TfidfVectorizer(stop_words=sw,tokenizer=tokenize, \n",
    "                          min_df= 0.001, max_df=0.9, \n",
    "                          ngram_range=(1,2))\n",
    "    tfidf = vect.fit_transform(ff_train)\n",
    "    tree = dtc(max_depth=abs(params['mx_depth']), \n",
    "               min_samples_split= 0.15,\n",
    "               max_features= 0.82\n",
    "              )\n",
    "\n",
    "    scores = cvt(tree, tfidf, ff_train_a, cv = 4, return_train_score= True, scoring = 'f1_macro', )\n",
    "    test_s = scores['test_score'].mean()\n",
    "    train_s = scores['train_score'].mean()\n",
    "    f_score = 1.0 - float(test_s) + float(abs(train_s-test_s))/2.0\n",
    "    \n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-02-27 15:02:45,784] Finished trial 10 / 25. Current best value is 0.3113213345048802 with parameters: {'mx_depth': 10.0}.\n",
      "[I 2019-02-27 15:02:46,984] Finished trial 10 / 25. Current best value is 0.21866960924507006 with parameters: {'mx_depth': 90.0}.\n",
      "[I 2019-02-27 15:02:55,453] Finished trial 20 / 25. Current best value is 0.21866960924507006 with parameters: {'mx_depth': 90.0}.\n",
      "[I 2019-02-27 15:02:56,591] Finished trial 20 / 25. Current best value is 0.21722007003087074 with parameters: {'mx_depth': 80.0}.\n"
     ]
    }
   ],
   "source": [
    "study2 = optuna.create_study()\n",
    "study2.optimize(objective3, n_trials=25, n_jobs = -1, verb_pace = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'_min': 0.0010076069969777687, '_max': 0.893393602554536, 'mx_depth': 80.0, 'mn_sp': 0.1550354937299351, 'mx_feat': 0.8211110248572838}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('tuned_parameters/decison_tree_augmented.pkl', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
