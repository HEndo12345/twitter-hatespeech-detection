{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from functions import *\n",
    "from process_text import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and save answers\n",
    "test_tweets = pd.read_csv('hatespeech-test.csv', index_col = 0)\n",
    "train_tweets = pd.read_csv('hatespeech-train.csv', index_col = 0)\n",
    "\n",
    "all_separated = [test_tweets, train_tweets]\n",
    "all_separated = [dic[\"tweet\"].values.tolist() for dic in all_separated]\n",
    "answers = [np.identity(3)[x['class'].values.tolist()] for x in [test_tweets, train_tweets]]\n",
    "answers2 = [x['class'].values.tolist() for x in [test_tweets, train_tweets]]\n",
    "save_pkl('cleaned_corpus/answer_data.pkl', answers)\n",
    "save_pkl('cleaned_corpus/org_answer_data.pkl', answers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4500\n",
       "2    3600\n",
       "0    1260\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "2    400\n",
       "0    140\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040/10400\n",
      "2080/10400\n",
      "3120/10400\n",
      "4160/10400\n",
      "5200/10400\n",
      "6240/10400\n",
      "7280/10400\n",
      "8320/10400\n",
      "9360/10400\n",
      "10400/10400\n"
     ]
    }
   ],
   "source": [
    "length = len(all_separated[0])+ len(all_separated[1])\n",
    "counter = 0\n",
    "tokenized = []\n",
    "client = nlp_client()\n",
    "\n",
    "for sets in all_separated:\n",
    "    data = []\n",
    "    for tweet in sets:\n",
    "        text = filter_tw(tweet)       \n",
    "        text = client.annotate(text)\n",
    "        text = additional_fix(text, client)\n",
    "        data.append(text)\n",
    "        counter += 1\n",
    "        if counter %1040 == 0: print(str(counter)+'/'+ str(length))\n",
    "        \n",
    "    tokenized.append(data)\n",
    "\n",
    "save_pkl('cleaned_corpus/base_cleaned.pkl', tokenized)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = gen_model_input(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('cleaned_corpus/base_model_input.pkl', vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(dest):\n",
    "    with open(dest, 'r', encoding = 'utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = read_txt('trans/transed/fr_en.txt')\n",
    "gr = read_txt('trans/transed/gr_en.txt')\n",
    "du = read_txt('trans/transed/du_en.txt')\n",
    "\n",
    "fr_n = read_txt('trans/transed/fr_en_n.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hate = []\n",
    "for lang in [fr, gr, du]:\n",
    "    lang = [x for x in lang.split('\\n') if len(x) != 0]\n",
    "    trans_hate.extend(lang)\n",
    "trans_neither = fr_n.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(trans_hate)\n",
    "add_hate = trans_hate[:4500-1260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/3240\n",
      "1000/3240\n",
      "1500/3240\n",
      "2000/3240\n",
      "2500/3240\n",
      "3000/3240\n",
      "3500/3240\n",
      "4000/3240\n"
     ]
    }
   ],
   "source": [
    "length = len(add_hate)\n",
    "counter = 0\n",
    "client = nlp_client()\n",
    "add_data = []\n",
    "for sets in [add_hate, trans_neither]:\n",
    "    for tweet in sets:\n",
    "        text = client.annotate(tweet)\n",
    "        text = additional_fix(text, client)\n",
    "        text = [re.sub('<answer>', '<reply>', word.lower()) for word in text]\n",
    "        add_data.append(text)\n",
    "        counter += 1\n",
    "        if counter %500 == 0: print(str(counter)+'/'+ str(length))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pkl('cleaned_corpus/base_cleaned.pkl')\n",
    "test, train = data\n",
    "test_a, train_a = answers\n",
    "test_a2, train_a2 = answers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "train_X = deepcopy(train)\n",
    "train_X.extend(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = (test, train_X)\n",
    "save_pkl('cleaned_corpus/augmented_corpus.pkl', new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_input = gen_model_input(new_corpus)\n",
    "save_pkl('cleaned_corpus/augmented_model_input.pkl', m_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_hate_ans = np.array([[1.0, 0.0, 0.0] for _ in range(len(add_hate))])\n",
    "add_nei_ans = np.array([[0.0, 0.0, 1.0] for _ in range(len(trans_neither))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_oha = np.append(train_a, add_hate_ans, axis = 0)\n",
    "new_oha = np.append(new_oha, add_nei_ans, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oha = (test_a, new_oha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('cleaned_corpus/augmented_ans.pkl', oha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_org_a = np.argmax(new_oha, axis = 1)\n",
    "new_ans = (test_a2, new_org_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('cleaned_corpus/augmented_org_ans.pkl', new_ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
